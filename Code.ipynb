{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VKdz6IYQFhI4",
        "IzogWuGfF7Ou",
        "JpXF5uI9Gee4",
        "ONd_Ot-7GoIk"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h2>Q Learning Tutorial Jupyter Notebook</h2>\n",
        "  <h2>Adapted by Andy (Wen-Chung) Cheng for the Reinforcement Learning for professional course at Florida Atlantic University</h2>\n",
        "</div>"
      ],
      "metadata": {
        "id": "NhFrfnPB_20Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXi9JMZ6n4ut"
      },
      "source": [
        "# Importing packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RYzlyWAjn4uw"
      },
      "outputs": [],
      "source": [
        "# Array math\n",
        "import numpy as np\n",
        "\n",
        "# Iteration tracking\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Type hinting\n",
        "from typing import Tuple\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "\n",
        "# Os traversal\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For rendering Greek letters in Latex for plotting"
      ],
      "metadata": {
        "id": "UXZmfsUUmhTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
        "matplotlib.rcParams['text.usetex'] = True\n",
        "matplotlib.rcParams[\"text.latex.preamble\"]  = r\"\\usepackage{cmbright}\"\n",
        "matplotlib.rcParams.update(matplotlib.rcParamsDefault)"
      ],
      "metadata": {
        "id": "dbcL4Z5xxTWq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FMbvN_6n4uz"
      },
      "source": [
        "# Defining the ploting functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Array Index to Matplot Coords Converter"
      ],
      "metadata": {
        "id": "VKdz6IYQFhI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def array_index_to_matplot_coords(i: int, j: int, n_cols: int) -> Tuple[int, int]:\n",
        "    \"\"\"Converts an array index to a matplot coordinate\"\"\"\n",
        "    x = j\n",
        "    y = n_cols - i - 1\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "nYRZ95edFoi-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Maze Plotter"
      ],
      "metadata": {
        "id": "IzogWuGfF7Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_matrix(\n",
        "    M: np.array,\n",
        "    goal_coords: list = [],\n",
        "    hole_coords: list = [],\n",
        "    start_coords: list = [],\n",
        "    highlight_coords: list = [],\n",
        "    img_width: int = 5,\n",
        "    img_height: int = 5,\n",
        "    title: str = None,\n",
        "    filename: str = None,\n",
        "    ) -> None:\n",
        "    \"\"\"\n",
        "    Plots a matrix as an image.\n",
        "    \"\"\"\n",
        "    height, width = M.shape\n",
        "\n",
        "    fig = plt.figure(figsize=(img_width, img_width))\n",
        "    ax = fig.add_subplot(111, aspect='equal')\n",
        "\n",
        "    for x in range(height):\n",
        "        for y in range(width):\n",
        "            # By default, the (0, 0) coordinate in matplotlib is the bottom left corner,\n",
        "            # so we need to invert the y coordinate to plot the matrix correctly\n",
        "            matplot_x, matplot_y = array_index_to_matplot_coords(x, y, height)\n",
        "\n",
        "            # If there is a tuple of (x, y) in the goal_coords list, we color the cell gray\n",
        "            if (x, y) in goal_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='lightgreen'))\n",
        "            # If there is a tuple of (x, y) in the hole_coords list, we color the cell salmon\n",
        "            elif (x, y) in hole_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='salmon'))\n",
        "            # If there is a tuple of (x, y) in the start_coords list, we color the cell yellow\n",
        "            elif (x, y) in start_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='yellow'))\n",
        "            # If there is a tuple of (x, y) in the highlight_coords list, we color the cell lightblue\n",
        "            elif (x, y) in highlight_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='lightblue'))\n",
        "\n",
        "            ax.annotate(str(M[x][y]), xy=(matplot_x, matplot_y), ha='center', va='center')\n",
        "\n",
        "    offset = .5\n",
        "    ax.set_xlim(-offset, width - offset)\n",
        "    ax.set_ylim(-offset, height - offset)\n",
        "\n",
        "    ax.hlines(y=np.arange(height+1)- offset, xmin=-offset, xmax=width-offset)\n",
        "    ax.vlines(x=np.arange(width+1) - offset, ymin=-offset, ymax=height-offset)\n",
        "\n",
        "    plt.title(title)\n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "nR3DZOa1F_4d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_state_visits(\n",
        "        S: np.array,\n",
        "        visit_dict: dict,\n",
        "        img_width: int = 5,\n",
        "        img_height: int = 5,\n",
        "        ):\n",
        "    \"\"\"\n",
        "    Plots the states and colors them by the number of visits.\n",
        "\n",
        "    The more visits a state has, the darker the color.\n",
        "    \"\"\"\n",
        "    # Get the number of rows and columns\n",
        "    n_rows, n_cols = S.shape\n",
        "    # Create a new matrix to hold the number of visits\n",
        "    V = np.zeros((n_rows, n_cols))\n",
        "    # Iterate through the visit dictionary and update the V matrix\n",
        "    for s, visits in visit_dict.items():\n",
        "        # Converting the state to an array index\n",
        "        s_index = np.where(S == s)\n",
        "\n",
        "        row, col = s_index[0][0], s_index[1][0]\n",
        "\n",
        "        V[row, col] = visits\n",
        "\n",
        "    fig = plt.figure(figsize=(img_width, img_height))\n",
        "    ax = fig.add_subplot(111, aspect='equal')\n",
        "\n",
        "    # Ploting the matrix\n",
        "    sns.heatmap(V, cmap='Blues', cbar=False, annot=True, fmt='.0f', ax=ax)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dzza8DgcGP4A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Policy Plotter"
      ],
      "metadata": {
        "id": "JpXF5uI9Gee4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the ploting function for the policy\n",
        "def plot_policy(\n",
        "        S: np.ndarray,\n",
        "        policy: dict,\n",
        "        goal_coords: tuple,\n",
        "        wall_coords: list,\n",
        "        start_coords: tuple,\n",
        "        optimal_policy_path: list,\n",
        "        title: str,\n",
        "        img_width: int = 6,\n",
        "        img_height: int = 6\n",
        "        ):\n",
        "    height, width = S.shape\n",
        "\n",
        "    fig = plt.figure(figsize=(img_width, img_height))\n",
        "    ax = fig.add_subplot(111, aspect='equal')\n",
        "    for x in range(height):\n",
        "        for y in range(width):\n",
        "            matplot_x, matplot_y = array_index_to_matplot_coords(x, y, height)\n",
        "\n",
        "            # If there is a tuple of (x, y) in the hole_coords list, we color the cell gray\n",
        "            if (x, y) in wall_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='gray'))\n",
        "\n",
        "            # If there is a tuple of (x, y) in the goal_coords list, we color the cell yellow\n",
        "            elif (x, y) in goal_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='lightgreen'))\n",
        "\n",
        "            else:\n",
        "                try:\n",
        "                    # If there is a tuple of (x, y) in the start_coords list, we color the cell green\n",
        "                    if (x, y) in start_coords:\n",
        "                        ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='yellow'))\n",
        "\n",
        "                        # Adding the arrows to the plot\n",
        "                        if 0 == policy[S[x, y]]:\n",
        "                            plt.arrow(matplot_x, matplot_y, 0, 0.3, head_width = 0.05, head_length = 0.05)\n",
        "                        if 1 == policy[S[x, y]]:\n",
        "                            plt.arrow(matplot_x, matplot_y, 0, -0.3, head_width = 0.05, head_length = 0.05)\n",
        "                        if 2 == policy[S[x, y]]:\n",
        "                            plt.arrow(matplot_x, matplot_y, -0.3, 0, head_width = 0.05, head_length = 0.05)\n",
        "                        if 3 == policy[S[x, y]]:\n",
        "                            plt.arrow(matplot_x, matplot_y, 0.3, 0, head_width = 0.05, head_length = 0.05)\n",
        "\n",
        "                    elif (x, y) in optimal_policy_path:\n",
        "                        ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='lightblue'))\n",
        "\n",
        "                        # Adding the arrows to the plot\n",
        "                        if 0 == policy[S[x, y]]:\n",
        "                            plt.arrow(matplot_x, matplot_y, 0, 0.3, head_width = 0.05, head_length = 0.05)\n",
        "                        if 1 == policy[S[x, y]]:\n",
        "                            plt.arrow(matplot_x, matplot_y, 0, -0.3, head_width = 0.05, head_length = 0.05)\n",
        "                        if 2 == policy[S[x, y]]:\n",
        "                            plt.arrow(matplot_x, matplot_y, -0.3, 0, head_width = 0.05, head_length = 0.05)\n",
        "                        if 3 == policy[S[x, y]]:\n",
        "                            plt.arrow(matplot_x, matplot_y, 0.3, 0, head_width = 0.05, head_length = 0.05)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error: {e}\")\n",
        "                    print(f\"Current x and y: {x}, {y}\")\n",
        "\n",
        "    offset = .5\n",
        "    ax.set_xlim(-offset, width - offset)\n",
        "    ax.set_ylim(-offset, height - offset)\n",
        "\n",
        "    ax.hlines(y=np.arange(height+1)- offset, xmin=-offset, xmax=width-offset)\n",
        "    ax.vlines(x=np.arange(width+1) - offset, ymin=-offset, ymax=height-offset)\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qggTMiMTGi-R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q Table Plotter"
      ],
      "metadata": {
        "id": "ONd_Ot-7GoIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the ploting function for the policy\n",
        "def plot_Q_Table(\n",
        "        S: np.ndarray,\n",
        "        Q: np.ndarray,\n",
        "        goal_coords: tuple,\n",
        "        wall_coords: list,\n",
        "        start_coords: tuple,\n",
        "        title: str,\n",
        "        img_width: int = 6,\n",
        "        img_height: int = 6,\n",
        "        filename: str = None\n",
        "        ):\n",
        "    height, width = S.shape\n",
        "\n",
        "    fig = plt.figure(figsize=(img_width, img_height))\n",
        "    ax = fig.add_subplot(111, aspect='equal')\n",
        "    for x in range(height):\n",
        "        for y in range(width):\n",
        "            matplot_x, matplot_y = array_index_to_matplot_coords(x, y, height)\n",
        "\n",
        "            # If there is a tuple of (x, y) in the hole_coords list, we color the cell gray\n",
        "            if (x, y) in wall_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='gray'))\n",
        "\n",
        "            # If there is a tuple of (x, y) in the goal_coords list, we color the cell yellow\n",
        "            elif (x, y) in goal_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='lightgreen'))\n",
        "\n",
        "            else:\n",
        "                try:\n",
        "                    # If there is a tuple of (x, y) in the start_coords list, we color the cell green\n",
        "                    if (x, y) in start_coords:\n",
        "                        ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='yellow'))\n",
        "\n",
        "\n",
        "                    plt.arrow(matplot_x, matplot_y, 0, 0.2, head_width = 0.05, head_length = 0.05)\n",
        "                    ax.annotate(f\"{Q[S[x, y]][0]:.2f}\", xy=(matplot_x, matplot_y + 0.5), ha='center', va='top')\n",
        "\n",
        "                    plt.arrow(matplot_x, matplot_y, 0, -0.2, head_width = 0.05, head_length = 0.05)\n",
        "                    ax.annotate(f\"{Q[S[x, y]][1]:.2f}\", xy=(matplot_x, matplot_y - 0.5), ha='center', va='bottom')\n",
        "\n",
        "                    plt.arrow(matplot_x, matplot_y, -0.2, 0, head_width = 0.05, head_length = 0.05)\n",
        "                    ax.annotate(f\"{Q[S[x, y]][2]:.2f}\", xy=(matplot_x - 0.5, matplot_y), ha='left', va='center')\n",
        "\n",
        "                    plt.arrow(matplot_x, matplot_y, 0.2, 0, head_width = 0.05, head_length = 0.05)\n",
        "                    ax.annotate(f\"{Q[S[x, y]][3]:.2f}\", xy=(matplot_x + 0.5, matplot_y), ha='right', va='center')\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error: {e}\")\n",
        "                    print(f\"Current x and y: {x}, {y}\")\n",
        "\n",
        "    offset = .5\n",
        "    ax.set_xlim(-offset, width - offset)\n",
        "    ax.set_ylim(-offset, height - offset)\n",
        "\n",
        "    ax.hlines(y=np.arange(height+1)- offset, xmin=-offset, xmax=width-offset)\n",
        "    ax.vlines(x=np.arange(width+1) - offset, ymin=-offset, ymax=height-offset)\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "-DDb71zeGrfq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6e3HDjWJn4uz"
      },
      "outputs": [],
      "source": [
        "# Defining the ploting function for the policy\n",
        "def plot_V_Table(\n",
        "        S: np.ndarray,\n",
        "        Q: np.ndarray,\n",
        "        goal_coords: tuple,\n",
        "        wall_coords: list,\n",
        "        start_coords: tuple,\n",
        "        title: str,\n",
        "        img_width: int = 6,\n",
        "        img_height: int = 6,\n",
        "        filename: str = None\n",
        "        ):\n",
        "    height, width = S.shape\n",
        "\n",
        "    fig = plt.figure(figsize=(img_width, img_height))\n",
        "    ax = fig.add_subplot(111, aspect='equal')\n",
        "    for x in range(height):\n",
        "        for y in range(width):\n",
        "            matplot_x, matplot_y = array_index_to_matplot_coords(x, y, height)\n",
        "\n",
        "            # If there is a tuple of (x, y) in the hole_coords list, we color the cell gray\n",
        "            if (x, y) in wall_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='gray'))\n",
        "\n",
        "            # If there is a tuple of (x, y) in the goal_coords list, we color the cell yellow\n",
        "            elif (x, y) in goal_coords:\n",
        "                ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='lightgreen'))\n",
        "\n",
        "            else:\n",
        "                try:\n",
        "                    # If there is a tuple of (x, y) in the start_coords list, we color the cell green\n",
        "                    if (x, y) in start_coords:\n",
        "                        ax.add_patch(matplotlib.patches.Rectangle((matplot_x - 0.5, matplot_y - 0.5), 1, 1, facecolor='yellow'))\n",
        "\n",
        "\n",
        "                    ax.annotate(f\"{max(Q[S[x, y]]):.2f}\", xy=(matplot_x, matplot_y), ha='center', va='center')\n",
        "\n",
        "                    # Adding the arrows to the plot\n",
        "                    if 0 == np.argmax(Q[S[x, y]]):\n",
        "                        plt.arrow(matplot_x, matplot_y + 0.1, 0, 0.3, head_width = 0.05, head_length = 0.05)\n",
        "                    if 1 == np.argmax(Q[S[x, y]]):\n",
        "                        plt.arrow(matplot_x, matplot_y - 0.1, 0, -0.3, head_width = 0.05, head_length = 0.05)\n",
        "                    if 2 == np.argmax(Q[S[x, y]]):\n",
        "                        plt.arrow(matplot_x - 0.1, matplot_y, -0.3, 0, head_width = 0.05, head_length = 0.05)\n",
        "                    if 3 == np.argmax(Q[S[x, y]]):\n",
        "                        plt.arrow(matplot_x + 0.1, matplot_y, 0.3, 0, head_width = 0.05, head_length = 0.05)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error: {e}\")\n",
        "                    print(f\"Current x and y: {x}, {y}\")\n",
        "\n",
        "    offset = .5\n",
        "    ax.set_xlim(-offset, width - offset)\n",
        "    ax.set_ylim(-offset, height - offset)\n",
        "\n",
        "    ax.hlines(y=np.arange(height+1)- offset, xmin=-offset, xmax=width-offset)\n",
        "    ax.vlines(x=np.arange(width+1) - offset, ymin=-offset, ymax=height-offset)\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The agent\n",
        "\n",
        "The agent will be an object created by the class `Agent`. All the uptades of the q table will be done internally in the agent object."
      ],
      "metadata": {
        "id": "4GbXum479qUV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_B3txUUGn4u0"
      },
      "outputs": [],
      "source": [
        "# steps to goal plot\n",
        "# add comment about where to add training script\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        nrow_maze: int,\n",
        "        ncol_maze: int,\n",
        "        actions: list = [0, 1, 2, 3],\n",
        "        rewards: dict = {\n",
        "            'step': -1,\n",
        "            'wall': -10,\n",
        "            'goal': 10,\n",
        "        },\n",
        "        gamma: float = 0.9,\n",
        "        alpha: float = 0.1,\n",
        "        epsilon: float = 0.1,\n",
        "        seed: int = 42,\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        Creates an agent for the maze environment.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        nrow_maze : int\n",
        "            The number of rows in the maze.\n",
        "        ncol_maze : int\n",
        "            The number of columns in the maze.\n",
        "        actions : list, optional\n",
        "            A list of actions that the agent can take. The default is [0, 1, 2, 3].\n",
        "            0: Up\n",
        "            1: Down\n",
        "            2: Left\n",
        "            3: Right\n",
        "        rewards : dict, optional\n",
        "            A dictionary of rewards for the agent. The default is {'step': -1, 'wall': -10, 'goal': 10}.\n",
        "        gamma : float, optional\n",
        "            The discount factor. The default is 0.9.\n",
        "        alpha : float, optional\n",
        "            The learning rate. The default is 0.1.\n",
        "        epsilon : float, optional\n",
        "            The exploration rate. The default is 0.1.\n",
        "        seed : int, optional\n",
        "            The seed for the random generator. The default is 42.\n",
        "        \"\"\"\n",
        "        self.nrow_maze = nrow_maze\n",
        "        self.ncol_maze = ncol_maze\n",
        "        self.rewards = rewards\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.seed = seed\n",
        "        self.actions = actions\n",
        "\n",
        "        # By default, the starting index is 0 0\n",
        "        self.start_state = 0\n",
        "\n",
        "        # By default, the steps to goal is 0\n",
        "        self.steps_to_goal = 0\n",
        "\n",
        "        # Initialize an empty list of steps to goals for all episodes\n",
        "        self.list_steps_to_goals = []\n",
        "\n",
        "        # By default, the goal index is the last index\n",
        "        self.goal_state = nrow_maze * ncol_maze - 1\n",
        "\n",
        "        # Creating the random generator with a fixed seed\n",
        "        self.random_generator = np.random.default_rng(seed)\n",
        "\n",
        "        # Creating the maze; We will denote it internaly as S\n",
        "        self.init_S_table()\n",
        "\n",
        "        # Initiating the Q-table\n",
        "        self.init_Q_table()\n",
        "\n",
        "        # Saving the initial past_action and past_state\n",
        "        self.past_action = None\n",
        "        self.past_state = None\n",
        "\n",
        "        # Creating the action name dictionary\n",
        "        self.action_name_dict = {\n",
        "            0: 'up',\n",
        "            1: 'down',\n",
        "            2: 'left',\n",
        "            3: 'right',\n",
        "        }\n",
        "\n",
        "        # Counter for the number of times our agent has seen the terminal state\n",
        "        self.num_goal_reached = 0\n",
        "\n",
        "        # Counter for each state and how many times the agent visited each\n",
        "        self.state_visit_counter = {}\n",
        "\n",
        "        # Empty dictionary of states visition paths\n",
        "        self.state_visit_paths = {}\n",
        "\n",
        "        # Empty dictionary of Q values\n",
        "        self.Q_dict = {}\n",
        "\n",
        "        # Placeholder for the current episode of learning\n",
        "        self.current_episode = 0\n",
        "\n",
        "\n",
        "        # Defining the path to intermediate images\n",
        "        self.path_to_images_V = \"q-learning-V-Table_Progress\"\n",
        "\n",
        "        # Defining the path to intermediate images\n",
        "        self.path_to_images_Q = \"q-learning-Q-Table_Progress\"\n",
        "\n",
        "    def increment_state_visit(self, state) -> None:\n",
        "        \"\"\"\n",
        "        Increments the state visit counter for the state.\n",
        "        \"\"\"\n",
        "        if state in self.state_visit_counter:\n",
        "            self.state_visit_counter[state] += 1\n",
        "        else:\n",
        "            self.state_visit_counter[state] = 1\n",
        "\n",
        "    def get_most_recent_action(self) -> str:\n",
        "        \"\"\"\n",
        "        Returns the name of the most recent action.\n",
        "        \"\"\"\n",
        "        return self.action_name_dict[self.past_action]\n",
        "\n",
        "    def init_S_table(self):\n",
        "        \"\"\"\n",
        "        Creates an internal S table where the rows of the table are\n",
        "        the states and the columns are the actions.\n",
        "        \"\"\"\n",
        "        self.S = np.arange(0, self.nrow_maze * self.ncol_maze).reshape(self.nrow_maze, self.ncol_maze)\n",
        "\n",
        "    def init_Q_table(self):\n",
        "        \"\"\"\n",
        "        Creates an internal q table where the rows of the table are\n",
        "        the states and the columns are the actions.\n",
        "        \"\"\"\n",
        "        self.Q = np.zeros((self.S.size, len(self.actions)))\n",
        "\n",
        "    def init_reward_dict(self):\n",
        "        \"\"\"\n",
        "        Creates a dictionary where the keys are the states and the values are the rewards for transitioniting to that state.\n",
        "        \"\"\"\n",
        "        if self.rewards.get('step') is None:\n",
        "            raise ValueError(\"You must specify a reward for taking a step.\")\n",
        "        else:\n",
        "            self.reward_dict = {s: self.rewards['step'] for s in self.S.flatten()}\n",
        "\n",
        "        if self.rewards.get('goal') is None:\n",
        "            raise ValueError(\"You must specify a reward for reaching the goal state.\")\n",
        "        else:\n",
        "            self.reward_dict[self.goal_state] = self.rewards['goal']\n",
        "\n",
        "        if self.rewards.get('wall') is not None:\n",
        "            # Setting the reward for the wall states\n",
        "            for wall_state in self.wall_states:\n",
        "                self.reward_dict[wall_state] = self.rewards['wall']\n",
        "\n",
        "    def init_maze(self, maze_density: int = None):\n",
        "        \"\"\"\n",
        "        Creates an array of states in a maze environment.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        maze : np.array\n",
        "            A 2D array of states in a maze environment.\n",
        "        wall_coords : list\n",
        "            A 1D array of wall states in the maze environment.\n",
        "        start_coords: tuple\n",
        "            A tuple of start coordinates in the maze environment.\n",
        "        goal_coords: tuple\n",
        "            A tuple of goal coordinates in the maze environment.\n",
        "        \"\"\"\n",
        "        # If maze_density is None we will create walls in 20% of the maze\n",
        "        if maze_density is None:\n",
        "            maze_density = int(self.nrow_maze * self.ncol_maze * 0.2)\n",
        "\n",
        "        # Creating the wall states\n",
        "        wall_states = self.random_generator.choice(range(1, self.nrow_maze * self.ncol_maze), size=maze_density, replace=False)\n",
        "\n",
        "        # Getting the list of wall coordinates\n",
        "        wall_coords = [self.get_state_coords(s) for s in wall_states]\n",
        "\n",
        "        # Generating a starting state from the states that are NOT walls\n",
        "        start_state = self.random_generator.choice(np.setdiff1d(self.S, wall_states))\n",
        "\n",
        "        # Getting the starting coordinates\n",
        "        start_coords = self.get_state_coords(start_state)\n",
        "\n",
        "        # Generating a goal state from the states that are NOT walls and NOT the starting state\n",
        "        goal_state = self.random_generator.choice(np.setdiff1d(np.setdiff1d(self.S, wall_states), start_state))\n",
        "\n",
        "        # Getting the goal coordinates\n",
        "        goal_coords = self.get_state_coords(goal_state)\n",
        "\n",
        "        # Saving the wall coordinates, start coordinates, and goal coordinates\n",
        "        self.wall_coords = wall_coords\n",
        "        self.start_coords = [start_coords]\n",
        "        self.goal_coords = [goal_coords]\n",
        "\n",
        "        # Saving the indexes for the wall, start and goal states\n",
        "        self.wall_states = wall_states\n",
        "        self.start_state = start_state\n",
        "        self.goal_state = goal_state\n",
        "\n",
        "        # Initiating the reward dictionary\n",
        "        self.init_reward_dict()\n",
        "\n",
        "        # Initiating the agent\n",
        "        self.init_agent()\n",
        "\n",
        "    def get_state_index(self, row: int, col: int) -> int:\n",
        "        \"\"\"\n",
        "        Returns the state index given the state coordinates.\n",
        "\n",
        "        An inverse function of get_state_coords()\n",
        "        \"\"\"\n",
        "        if (row < 0 or row >= self.nrow_maze or col < 0 or col >= self.ncol_maze):\n",
        "            return -1\n",
        "        else:\n",
        "            return self.S[row][col]\n",
        "\n",
        "    def get_state_coords(self, s) -> tuple:\n",
        "        \"\"\"\n",
        "        Returns the state coordinates given the state index\n",
        "        \"\"\"\n",
        "        s_index = np.where(self.S == s)\n",
        "        if len(s_index[0]) == 0:\n",
        "            return -1, -1\n",
        "\n",
        "        return s_index[0][0], s_index[1][0]\n",
        "\n",
        "    def get_action(\n",
        "            self,\n",
        "            ) -> int:\n",
        "        \"\"\"\n",
        "        Returns a random action from the set of actions\n",
        "\n",
        "        The actions are:\n",
        "        0: up\n",
        "        1: down\n",
        "        2: left\n",
        "        3: right\n",
        "        \"\"\"\n",
        "        return self.random_generator.choice(self.actions)\n",
        "\n",
        "    def argmax(self, q_values: np.array):\n",
        "        \"\"\"argmax with random tie-breaking\n",
        "        Args:\n",
        "            q_values (Numpy array): the array of action values\n",
        "        Returns:\n",
        "            action (int): an action with the highest value\n",
        "        \"\"\"\n",
        "        top = float(\"-inf\")\n",
        "        ties = []\n",
        "\n",
        "        for i in range(len(q_values)):\n",
        "            if q_values[i] > top:\n",
        "                top = q_values[i]\n",
        "                ties = []\n",
        "\n",
        "            if q_values[i] == top:\n",
        "                ties.append(i)\n",
        "\n",
        "        return self.random_generator.choice(ties)\n",
        "\n",
        "    def get_greedy_action(self, state: int) -> int:\n",
        "        \"\"\"\n",
        "        Returns the greedy action given the current state\n",
        "        \"\"\"\n",
        "        # Getting the q values for the current state\n",
        "        q_values = self.Q[state]\n",
        "\n",
        "        # Getting the greedy action\n",
        "        greedy_action = self.argmax(q_values)\n",
        "\n",
        "        # Returning the greedy action\n",
        "        return greedy_action\n",
        "\n",
        "    def get_epsilon_greedy_action(self, state: int) -> int:\n",
        "        \"\"\"\n",
        "        Returns an epsilon greedy action\n",
        "        \"\"\"\n",
        "        if self.random_generator.random() < self.epsilon:\n",
        "            return self.get_action()\n",
        "        else:\n",
        "            return self.get_greedy_action(state)\n",
        "\n",
        "    # Logging of the agent paths\n",
        "    def log_agent_move(self, state: int):\n",
        "        \"\"\"\n",
        "        Logs the agent's move\n",
        "        \"\"\"\n",
        "        if self.state_visit_paths.get(self.current_episode, None) is None:\n",
        "            self.state_visit_paths[self.current_episode] = [state]\n",
        "        else:\n",
        "            self.state_visit_paths[self.current_episode].append(state)\n",
        "\n",
        "\n",
        "\n",
        "    def update_Q_table(self, new_state: int):\n",
        "        \"\"\"\n",
        "        Write your own code here to update the Q table\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    def get_next_state(self, s: int, action: int) -> int:\n",
        "        \"\"\"\n",
        "        Given the current state and the current action, returns the next state index\n",
        "        \"\"\"\n",
        "        # Getting the state coordinates\n",
        "        s_row, s_col = self.get_state_coords(s)\n",
        "\n",
        "        # Setting the boolean indicating that we have reached the terminal state\n",
        "        reached_terminal = False\n",
        "\n",
        "        # Getting the next state\n",
        "        next_state = -1\n",
        "        if action == 0:\n",
        "            next_state = self.get_state_index(s_row - 1, s_col)\n",
        "        elif action == 1:\n",
        "            next_state = self.get_state_index(s_row + 1, s_col)\n",
        "        elif action == 2:\n",
        "            next_state = self.get_state_index(s_row, s_col - 1)\n",
        "        elif action == 3:\n",
        "            next_state = self.get_state_index(s_row, s_col + 1)\n",
        "\n",
        "        # If next_state is a wall or the agent is out of bounds, we will stay in the same state\n",
        "        if (next_state == -1) or (next_state in self.wall_states):\n",
        "            return s, reached_terminal\n",
        "\n",
        "        # Incrementing the number of times we have visited the next state\n",
        "        self.increment_state_visit(next_state)\n",
        "\n",
        "        # If next_state is the goal state, we will return to the starting state\n",
        "        if next_state == self.goal_state:\n",
        "            # Incrementing the number of times our agent has reached the goal state\n",
        "            self.num_goal_reached += 1\n",
        "            reached_terminal = True\n",
        "\n",
        "        # Returning the next state\n",
        "        return next_state, reached_terminal\n",
        "\n",
        "    def init_agent(self):\n",
        "        \"\"\"\n",
        "        We will set the past state and past action as the starting state and action\n",
        "        \"\"\"\n",
        "        # Setting the previous state as the starting state\n",
        "        self.past_state = self.start_state\n",
        "        self.past_action = self.get_epsilon_greedy_action(self.past_state)\n",
        "        self.num_goal_reached = 0\n",
        "\n",
        "\n",
        "    def save_steps_to_goal_for_current_episode(self):\n",
        "        \"\"\"\n",
        "        Write your own code here to save the steps to goal for current episode\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def terminal_step(self, new_state: int):\n",
        "        \"\"\"\n",
        "        Updates the agent one last time and resets the agent to the starting position\n",
        "        \"\"\"\n",
        "        # Updating the Q table\n",
        "        self.update_Q_table(new_state)\n",
        "\n",
        "        # Resetting the agent\n",
        "        self.past_state = self.start_state\n",
        "        self.past_action = self.get_epsilon_greedy_action(self.past_state)\n",
        "\n",
        "\n",
        "        # save the steps taken to reach the goal for this episode, and reset steps to goal to 0 for next episode\n",
        "        self.save_steps_to_goal_for_current_episode()\n",
        "        self.steps_to_goal = 0\n",
        "\n",
        "        # Incrementing the number of episodes\n",
        "        self.current_episode += 1\n",
        "\n",
        "    def move_agent(self):\n",
        "        \"\"\"\n",
        "        The function that moves the agent to the next state\n",
        "        \"\"\"\n",
        "        # Getting the next state\n",
        "        next_state, reached_terminal = self.get_next_state(self.past_state, self.past_action)\n",
        "\n",
        "        # Adding the next state to the path\n",
        "        self.log_agent_move(next_state)\n",
        "\n",
        "        # Updating the Q table\n",
        "        if not reached_terminal:\n",
        "            # Checking if the past_state is the same as the next_state; If that is true, it means our agent hit a wall\n",
        "            # or went out of bounds\n",
        "            if self.past_state != next_state:\n",
        "                self.update_Q_table(next_state)\n",
        "\n",
        "            # Setting the past_state as the next_state\n",
        "            self.past_state = next_state\n",
        "\n",
        "            # Getting the next action\n",
        "            self.past_action = self.get_epsilon_greedy_action(self.past_state)\n",
        "\n",
        "            # add 1 step\n",
        "            self.steps_to_goal += 1\n",
        "\n",
        "        else:\n",
        "            # add 1 step\n",
        "            self.steps_to_goal += 1\n",
        "            self.terminal_step(next_state)\n",
        "\n",
        "    def train_episodes(self, num_episodes: int):\n",
        "        \"\"\"\n",
        "        Function that trains the agent for one episode\n",
        "        \"\"\"\n",
        "        # Calculating the episode number to end the training\n",
        "        end_episode = self.current_episode + num_episodes - 1\n",
        "\n",
        "        # Moving the agent until we reach the goal state\n",
        "        while self.current_episode != end_episode:\n",
        "\n",
        "            print(f\"Episode {self.current_episode}\")\n",
        "\n",
        "            self.move_agent()\n",
        "\n",
        "    def create_policy(self):\n",
        "        \"\"\"\n",
        "        Creates a policy dictionary where the key is the state and the value is the action\n",
        "        based on the Q table\n",
        "        \"\"\"\n",
        "        # Creating the policy dictionary\n",
        "        self.policy = {}\n",
        "\n",
        "        # Looping through the states\n",
        "        for state in range(self.S.size):\n",
        "            # Getting the greedy action\n",
        "            greedy_action = self.argmax(self.Q[state])\n",
        "\n",
        "            # Adding the state and action to the policy dictionary\n",
        "            self.policy[state] = greedy_action\n",
        "\n",
        "    def create_optimal_policy_path(self):\n",
        "        \"\"\"\n",
        "        Creates the path of the optimal policy, starting from the starting state\n",
        "        \"\"\"\n",
        "        # Creating the policy path\n",
        "        self.optimal_policy_path = [self.start_state]\n",
        "        self.optimal_policy_path_coords = [self.get_state_coords(self.start_state)]\n",
        "\n",
        "        # Getting the current state\n",
        "        current_state = self.start_state\n",
        "\n",
        "        # Looping through the states\n",
        "        while current_state != self.goal_state:\n",
        "            # Getting the next state\n",
        "            next_state, _ = self.get_next_state(current_state, self.policy[current_state])\n",
        "\n",
        "            # Adding the next state to the path\n",
        "            self.optimal_policy_path.append(next_state)\n",
        "            self.optimal_policy_path_coords.append(self.get_state_coords(next_state))\n",
        "\n",
        "            # Setting the current state as the next state\n",
        "            current_state = next_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg4d1mdzn4u2"
      },
      "source": [
        "# Agent learning\n",
        "\n",
        "First, let us create the agent object and initiate the maze environment for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Tgvy3Pc9n4u2",
        "outputId": "b08c5fec-6643-4a27-9664-62d8179fd377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAFECAYAAACatB8SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvsklEQVR4nO3de1wU9f4/8NcCsgsmIIIsFIqKoaiAwoGDXcTcBOWY9qu8kSJfxfTISc+WF85DwUtFlimWfKNMRfOCt7QyAw1FU/EGUpbmVz0oXljwBitgi7Lz+8OHUxsXQWdYLq/n4zEPndnPfHh/Zpd5MTuzswpBEAQQERGRJCzMXQAREVFzwmAlIiKSEIOViIhIQgxWIiIiCTFYiYiIJMRgJSIikhCDlYiISEIMViIiIgkxWImIiCTEYCUiIpIQg5WoCUlJSYFCoYBCocCBAweqPC4IAtzd3aFQKPCPf/zDDBUSEYOVqAlSqVRYv359leX79u3D5cuXoVQqzVAVEQEMVqImafDgwdi8eTPu3btnsnz9+vXw9/eHWq02U2VExGAlaoJGjRqFGzduYPfu3eKyiooKbNmyBaNHj67SftGiRejbty/atWsHGxsb+Pv7Y8uWLSZtxo0bJ77N/Ndp7ty5YjuDwYD4+Hh4enpCqVTC3d0dM2bMgMFgkG28RE2JlbkLIKL68/DwQHBwMDZs2IBBgwYBAL7//nuUlJRg5MiR+Pjjj03aL126FC+99BIiIiJQUVGB1NRUvPbaa9ixYwfCw8MBAG+88QY0Go3JemlpaVi3bh3at28PADAajXjppZdw4MABTJw4Ed27d8fJkyexZMkS/N///R+2b98u/+CJGjuBiJqMVatWCQCEY8eOCcuWLRPatGkjlJeXC4IgCK+99prQv39/QRAEoWPHjkJ4eLi43oM2D1RUVAg9e/YUXnjhhRp/1tmzZwV7e3vhxRdfFO7duycIgiB8+eWXgoWFhfDjjz+atE1OThYACAcPHpRknERNGd8KJmqihg8fjjt37mDHjh24ffs2duzYUe3bwABgY2Mj/v/WrVsoKSnBc889h5ycnGrbl5WV4eWXX0bbtm2xYcMGWFpaAgA2b96M7t27o1u3brh+/bo4vfDCCwCAvXv3SjxKoqaHbwUTNVHOzs7QaDRYv349ysvLUVlZiVdffbXatjt27MA777yD3Nxck3OhCoWi2vbR0dE4f/48Dh06hHbt2onLz549i9OnT8PZ2bna9YqKih5jRETNA4OVqAkbPXo0oqOjodPpMGjQIDg4OFRp8+OPP+Kll17C888/j//93/+Fq6srWrVqhVWrVlX7kZ2lS5diw4YNWLt2Lfz8/EweMxqN6NWrFxYvXlxtPe7u7lIMi6hJY7ASNWEvv/wy3njjDRw+fBgbN26sts3WrVuhUqmQnp5u8vnWVatWVWn7448/4u2338a0adMQERFR5fEuXbrgp59+woABA2o82iVq6XiOlagJe+KJJ/Dpp59i7ty5GDJkSLVtLC0toVAoUFlZKS67cOFClSt4CwoKMHz4cDz77LP48MMPq+1r+PDhuHLlCpYvX17lsTt37qCsrOzRB0PUTPCIlaiJi4yMrPXx8PBwLF68GGFhYRg9ejSKioqQlJQET09P/Pzzz2K7N998E9euXcOMGTOQmppq0oePjw98fHwwZswYbNq0CZMmTcLevXvxzDPPoLKyEr/99hs2bdqE9PR0BAQEyDJOoqaCwUrUzL3wwgtYsWIF3n//fUybNg2dOnXCwoULceHCBZNgvXbtGiorK6HVaqv0ER8fDx8fH1hYWGD79u1YsmQJ1qxZg23btsHW1hadO3fG1KlT8fTTTzfk0IgaJYUgCIK5iyAiImoueI6ViIhIQgxWIiIiCTFYiYiIJCRrsO7fvx9DhgyBm5sbFArFQ2/QnZmZWe03a+h0OpN2SUlJ8PDwgEqlQlBQEI4ePSrjKIiIiOpO1mAtKyuDr68vkpKS6rXemTNnUFBQIE4PvlkDADZu3AitVov4+Hjk5OTA19cXoaGhvJUaERE1Cg12VbBCocC2bdswbNiwGttkZmaif//+uHXrVrW3ZgOAoKAg/O1vf8OyZcsA3L/Fmru7O/71r39h1qxZMlRORERUd43yc6x+fn4wGAzo2bMn5s6di2eeeQbA/S9yzs7ORmxsrNjWwsICGo0GWVlZNfZnMBhMbjxuNBpx8+ZNtGvXjrdlIyJqoQRBwO3bt+Hm5gYLC+newG1Uwerq6ork5GQEBATAYDDgiy++QEhICI4cOYI+ffrg+vXrqKyshIuLi8l6Li4u+O2332rsNyEhAfPmzZO7fCIiaoIuXbqEp556SrL+GlWwenl5wcvLS5zv27cvzp8/jyVLluDLL7985H5jY2NN7iZTUlKCDh064KffzqF9u7aPVTM1PXcq7qHfh/sAAPum94ONdaP6NaAG8OfXQNTEPLRqZeaCqMHdvQus+MQFVz4dhzZt2kjad6PfowQGBuLAgQMAACcnJ1haWqKwsNCkTWFhIdRqdY19KJVKk2/1eKB9u7ZQOzlKWzA1euUV92ChtAUAuDg5wpbB2uL8+TXQxlGFVta8AV1Lc7dCIb4GpD4l2Og/x5qbmwtXV1cAgLW1Nfz9/ZGRkSE+bjQakZGRgeDgYHOVSEREJJL1T/XS0lKcO3dOnM/Ly0Nubi4cHR3RoUMHxMbG4sqVK1izZg0AIDExEZ06dUKPHj3w+++/44svvsCePXuwa9cusQ+tVovIyEgEBAQgMDAQiYmJKCsrQ1RUlJxDISIiqhNZg/X48ePo37+/OP/gPGdkZCRSUlJQUFCA/Px88fGKigq89dZbuHLlCmxtbeHj44MffvjBpI8RI0bg2rVriIuLg06ng5+fH9LS0qpc0ERERGQOsgZrSEgIavuYbEpKisn8jBkzMGPGjIf2GxMTg5iYmMctj4iISHKN/hwrERFRU8JgJSIikhCDlYiISEIMViIiIgkxWImIiCTEYCUiIpIQg5WIiEhCDFYiIiIJMViJiIgkxGAlIiKSEIOViIhIQgxWIiIiCTFYiYiIJMRgJSIikhCDlYiISEIMViIiIgkxWImIiCTEYCUiIpIQg5WIiEhCDFYiIiIJMViJiIgkJGuw7t+/H0OGDIGbmxsUCgW2b99ea/uvvvoKL774IpydnWFnZ4fg4GCkp6ebtJk7dy4UCoXJ1K1bNxlHQUREVHeyBmtZWRl8fX2RlJRUp/b79+/Hiy++iJ07dyI7Oxv9+/fHkCFDcOLECZN2PXr0QEFBgTgdOHBAjvKJiIjqzUrOzgcNGoRBgwbVuX1iYqLJ/HvvvYevv/4a3377LXr37i0ut7KyglqtlqpMIiIiyTTqc6xGoxG3b9+Go6OjyfKzZ8/Czc0NnTt3RkREBPLz82vtx2AwQK/Xm0xERERyaNTBumjRIpSWlmL48OHisqCgIKSkpCAtLQ2ffvop8vLy8Nxzz+H27ds19pOQkAB7e3txcnd3b4jyiYioBWq0wbp+/XrMmzcPmzZtQvv27cXlgwYNwmuvvQYfHx+EhoZi586dKC4uxqZNm2rsKzY2FiUlJeJ06dKlhhgCERG1QLKeY31UqampmDBhAjZv3gyNRlNrWwcHBzz99NM4d+5cjW2USiWUSqXUZRIREVXR6I5YN2zYgKioKGzYsAHh4eEPbV9aWorz58/D1dW1AaojIiKqnaxHrKWlpSZHknl5ecjNzYWjoyM6dOiA2NhYXLlyBWvWrAFw/+3fyMhILF26FEFBQdDpdAAAGxsb2NvbAwDefvttDBkyBB07dsTVq1cRHx8PS0tLjBo1Ss6hEBER1YmsR6zHjx9H7969xY/KaLVa9O7dG3FxcQCAgoICkyt6P//8c9y7dw9TpkyBq6urOE2dOlVsc/nyZYwaNQpeXl4YPnw42rVrh8OHD8PZ2VnOoRAREdWJrEesISEhEAShxsdTUlJM5jMzMx/aZ2pq6mNWRUREJJ9Gd46ViIioKWOwEhERSYjBSkREJCEGKxERkYQYrERERBJisBIREUmIwUpERCQhBisREZGEGKxEREQSYrASERFJiMFKREQkIQYrERGRhBisREREEmKwEhERSYjBSkREJCEGKxERkYQYrERERBJisBIREUmIwUpERCQhBisREZGEGKwtUFJSEjw8PKBSqRAUFISjR4+auyRqQPv378eQIUPg5uYGhUKB7du3m7skamC7l+zGRwM+wswOMzH76dn44vUvUHi20NxlNRuyBuuj/AJnZmaiT58+UCqV8PT0REpKSpU2DIZHt3HjRmi1WsTHxyMnJwe+vr4IDQ1FUVGRuUujBlJWVgZfX18kJSWZuxQyk/MHz+PZ8c9iWvo0TP5qMox3jUh+JRmGMoO5S2sWZA3W+v4C5+XlITw8HP3790dubi6mTZuGCRMmID09XWzDYHg8ixcvRnR0NKKiouDt7Y3k5GTY2tpi5cqV5i6NGsigQYPwzjvv4OWXXzZ3KWQmk7ZMQtDoILh2d8WTPZ/E6KTRuHX5Fi7/dNncpTULsgZrfX+Bk5OT0alTJ3z00Ufo3r07YmJi8Oqrr2LJkiViGwbDo6uoqEB2djY0Go24zMLCAhqNBllZWWasjIjM6Y7+DgDA1sHWzJU0D43qHGtWVpbJTh8AQkNDxZ0+g+HxXL9+HZWVlXBxcTFZ7uLiAp1OZ6aqiMicjEYjtv1nGzoFdYKrt6u5y2kWrMxdwJ/pdLpqd/p6vR537tzBrVu3agyG3377rcZ+DQYDDIY/zh3o9XppCyciaqK2TN+CgtMFmLpzqrlLaTYa1RGrXBISEmBvby9O7u7u5i7JLJycnGBpaYnCQtOr/woLC6FWq81UFRGZy5YZW3Aq/RRivomBw5MO5i6n2WhUwapWq6vd6dvZ2cHGxuaRgyE2NhYlJSXidOnSJVnqb+ysra3h7++PjIwMcZnRaERGRgaCg4PNWBkRNSRBELBlxhac/O4kpnw9Be06tjN3Sc1KowrW4OBgk50+AOzevVvc6T9qMCiVStjZ2ZlMLZVWq8Xy5cuxevVqnD59GpMnT0ZZWRmioqLMXRo1kNLSUuTm5iI3NxfA/avxc3NzkZ+fb97CqMFsmb4Fxzcdx5jPx0D5hBL6Qj30hXpU3Kkwd2nNgqznWEtLS3Hu3Dlx/sEvsKOjIzp06IDY2FhcuXIFa9asAQBMmjQJy5Ytw4wZM/A///M/2LNnDzZt2oTvvvtO7EOr1SIyMhIBAQEIDAxEYmIig6EeRowYgWvXriEuLg46nQ5+fn5IS0urct6amq/jx4+jf//+4rxWqwUAREZGVvu5cWp+Dq48CABYNmSZyfJRy0YhaHSQOUpqVmQN1of9AhcUFJj8ldypUyd89913+Pe//42lS5fiqaeewhdffIHQ0FCxDYPh8cXExCAmJsbcZZCZhISEQBAEc5dBZpR4M9HcJTRrsgbrw36Bq/vrOCQkBCdOnKi1XwYDERE1Vo3qHCsREVFTx2AlIiKSEIOViIhIQgxWIiIiCTFYiYiIJMRgJSIikhCDlYiISEIMViIiIgkxWImIiCTEYCUiIpIQg5WIiEhCDFYiIiIJMViJiIgkxGAlIiKSEIOViIhIQgxWIiIiCTFYiYiIJMRgJSIikhCDlYiISEIMViIiIgkxWImIiCTEYCUiIpKQ7MGalJQEDw8PqFQqBAUF4ejRozW2DQkJgUKhqDKFh4eLbcaNG1fl8bCwMLmHQUREVCdWcna+ceNGaLVaJCcnIygoCImJiQgNDcWZM2fQvn37Ku2/+uorVFRUiPM3btyAr68vXnvtNZN2YWFhWLVqlTivVCrlGwQREVE9yHrEunjxYkRHRyMqKgre3t5ITk6Gra0tVq5cWW17R0dHqNVqcdq9ezdsbW2rBKtSqTRp17ZtWzmHQUREVGeyBWtFRQWys7Oh0Wj++GEWFtBoNMjKyqpTHytWrMDIkSPRunVrk+WZmZlo3749vLy8MHnyZNy4caPWfgwGA/R6vclEREQkB9mC9fr166isrISLi4vJchcXF+h0uoeuf/ToUfzyyy+YMGGCyfKwsDCsWbMGGRkZWLhwIfbt24dBgwahsrKyxr4SEhJgb28vTu7u7o82KCIiooeQ9Rzr41ixYgV69eqFwMBAk+UjR44U/9+rVy/4+PigS5cuyMzMxIABA6rtKzY2FlqtVpzX6/UMVyIikoVsR6xOTk6wtLREYWGhyfLCwkKo1epa1y0rK0NqairGjx//0J/TuXNnODk54dy5czW2USqVsLOzM5mIiIjkIFuwWltbw9/fHxkZGeIyo9GIjIwMBAcH17ru5s2bYTAY8Prrrz/051y+fBk3btyAq6vrY9dMRET0uGS9Klir1WL58uVYvXo1Tp8+jcmTJ6OsrAxRUVEAgLFjxyI2NrbKeitWrMCwYcPQrl07k+WlpaWYPn06Dh8+jAsXLiAjIwNDhw6Fp6cnQkND5RwKERFRnch6jnXEiBG4du0a4uLioNPp4Ofnh7S0NPGCpvz8fFhYmGb7mTNncODAAezatatKf5aWlvj555+xevVqFBcXw83NDQMHDsSCBQv4WVYiImoUZL94KSYmBjExMdU+lpmZWWWZl5cXBEGotr2NjQ3S09OlLI+IiEhSvFcwERGRhBisREREEmKwEhERSYjBSkREJCEGKxERkYQYrERERBJisBIREUmIwUpERCQhBisREZGEGKxEREQSYrASERFJiMFKREQkIQYrERGRhBisREREEmKwEhERSYjBSkREJCEGKxERkYQYrERERBJisBIREUmIwUpERCQhBisREZGEZA/WpKQkeHh4QKVSISgoCEePHq2xbUpKChQKhcmkUqlM2giCgLi4OLi6usLGxgYajQZnz56VexhERER1Imuwbty4EVqtFvHx8cjJyYGvry9CQ0NRVFRU4zp2dnYoKCgQp4sXL5o8/sEHH+Djjz9GcnIyjhw5gtatWyM0NBS///67nEMhIiKqEys5O1+8eDGio6MRFRUFAEhOTsZ3332HlStXYtasWdWuo1AooFarq31MEAQkJiZi9uzZGDp0KABgzZo1cHFxwfbt2zFy5Mh61Xen4h7KK+7Vax1q+v78nPP5b5n+/LzfvaswYyVkLnI+77IFa0VFBbKzsxEbGysus7CwgEajQVZWVo3rlZaWomPHjjAajejTpw/ee+899OjRAwCQl5cHnU4HjUYjtre3t0dQUBCysrJqDFaDwQCDwSDO6/V6AEC/D/fBQmn7WOOkpi3gnQxzl0Bm9tmyzuYugcymXJZeZXsr+Pr166isrISLi4vJchcXF+h0umrX8fLywsqVK/H1119j7dq1MBqN6Nu3Ly5fvgwA4nr16RMAEhISYG9vL07u7u6PMzQiIqIayfpWcH0FBwcjODhYnO/bty+6d++Ozz77DAsWLHjkfmNjY6HVasV5vV4Pd3d37Js+Hi5OFY9VMzU95RVKBLyzHgBwfPYA2Fo3ql8DagDlFffEdyuylPthqzCauSJqaOWCBYIMAbL0LdsexcnJCZaWligsLDRZXlhYWOM51L9q1aoVevfujXPnzgGAuF5hYSFcXV1N+vTz86uxH6VSCaVSWWW5jbUBttYM1pbM1tqKwdrC2SqMDFaSlGxvBVtbW8Pf3x8ZGX+cwzIajcjIyDA5Kq1NZWUlTp48KYZop06doFarTfrU6/U4cuRInfskIiKSk6x/qmu1WkRGRiIgIACBgYFITExEWVmZeJXw2LFj8eSTTyIhIQEAMH/+fPz973+Hp6cniouL8eGHH+LixYuYMGECgPtXDE+bNg3vvPMOunbtik6dOmHOnDlwc3PDsGHD5BwKERFRncgarCNGjMC1a9cQFxcHnU4HPz8/pKWliRcf5efnw8Lij4PmW7duITo6GjqdDm3btoW/vz8OHToEb29vsc2MGTNQVlaGiRMnori4GM8++yzS0tKq3EiCiIjIHBSCIAjmLqKh6fV62Nvbo+CaNdS8eKnFKa9QwjtuKwDg1PxQnmNtgcor7sE7Lh0A8JMqk+dYW6BywQK9SgJxKXE4SkpKYGdnJ1nfvFcwERGRhBisREREEmKwEhERSYjBSkREJCEGKxERkYQYrERERBJisBIREUmIwUpERCQhBisREZGEGKxEREQSYrASERFJiMFKREQkIQYrERGRhBisREREEmKwEhERSYjBSkREJCEGKxERkYQYrERERBJisBIREUmIwUpERCQhBisREZGEZA/WpKQkeHh4QKVSISgoCEePHq2x7fLly/Hcc8+hbdu2aNu2LTQaTZX248aNg0KhMJnCwsLkHgYREVGdyBqsGzduhFarRXx8PHJycuDr64vQ0FAUFRVV2z4zMxOjRo3C3r17kZWVBXd3dwwcOBBXrlwxaRcWFoaCggJx2rBhg5zDICIiqjNZg3Xx4sWIjo5GVFQUvL29kZycDFtbW6xcubLa9uvWrcM///lP+Pn5oVu3bvjiiy9gNBqRkZFh0k6pVEKtVotT27Zt5RwGERFRnckWrBUVFcjOzoZGo/njh1lYQKPRICsrq059lJeX4+7du3B0dDRZnpmZifbt28PLywuTJ0/GjRs3au3HYDBAr9ebTERERHKQLVivX7+OyspKuLi4mCx3cXGBTqerUx8zZ86Em5ubSTiHhYVhzZo1yMjIwMKFC7Fv3z4MGjQIlZWVNfaTkJAAe3t7cXJ3d3+0QRERET2ElbkLqMn777+P1NRUZGZmQqVSictHjhwp/r9Xr17w8fFBly5dkJmZiQEDBlTbV2xsLLRarTiv1+sZrkREJAvZjlidnJxgaWmJwsJCk+WFhYVQq9W1rrto0SK8//772LVrF3x8fGpt27lzZzg5OeHcuXM1tlEqlbCzszOZiIiI5CBbsFpbW8Pf39/kwqMHFyIFBwfXuN4HH3yABQsWIC0tDQEBAQ/9OZcvX8aNGzfg6uoqSd1ERESPQ9argrVaLZYvX47Vq1fj9OnTmDx5MsrKyhAVFQUAGDt2LGJjY8X2CxcuxJw5c7By5Up4eHhAp9NBp9OhtLQUAFBaWorp06fj8OHDuHDhAjIyMjB06FB4enoiNDRUzqEQERHViaznWEeMGIFr164hLi4OOp0Ofn5+SEtLEy9oys/Ph4XFH9n+6aefoqKiAq+++qpJP/Hx8Zg7dy4sLS3x888/Y/Xq1SguLoabmxsGDhyIBQsWQKlUyjkUIiKiOpH94qWYmBjExMRU+1hmZqbJ/IULF2rty8bGBunp6RJVRkREJD3eK5iIiEhCDFYiIiIJMViJiIgkxGAlIiKSEIOViIhIQgxWIiIiCTFYiYiIJMRgJSIikhCDlYiISEIMViIiIgkxWImIiCTEYCUiIpIQg5WIiEhCDFYiIiIJMViJiIgkxGAlIiKSEIOViIhIQgxWIiIiCTFYiYiIJMRgJSIikhCDtQX59FPAxwews7s/BQcD339v7qrInN5//30oFApMmzbN3KVQA5q/9xCs5y42mXp+ssrcZTUbVuYugBrOU08B778PdO0KCAKwejUwdChw4gTQo4e5q6OGduzYMXz22Wfw8fExdylkBt7O7ZA29lVx3sqCx1lSkX1LJiUlwcPDAyqVCkFBQTh69Git7Tdv3oxu3bpBpVKhV69e2Llzp8njgiAgLi4Orq6usLGxgUajwdmzZ+UcQrMxZAgwePD9YH36aeDdd4EnngAOHzZ3ZdTQSktLERERgeXLl6Nt27bmLofMwMrCAuo2rcXJqbWNuUtqNmQN1o0bN0Kr1SI+Ph45OTnw9fVFaGgoioqKqm1/6NAhjBo1CuPHj8eJEycwbNgwDBs2DL/88ovY5oMPPsDHH3+M5ORkHDlyBK1bt0ZoaCh+//13OYfS7FRWAqmpQFnZ/beEqWWZMmUKwsPDodFozF0Kmcm5m7fQcdFn8EpcgbFbdyK/WG/ukpoNWYN18eLFiI6ORlRUFLy9vZGcnAxbW1usXLmy2vZLly5FWFgYpk+fju7du2PBggXo06cPli1bBuD+0WpiYiJmz56NoUOHwsfHB2vWrMHVq1exfft2OYfSbJw8ef8oVakEJk0Ctm0DvL3NXRU1pNTUVOTk5CAhIcHcpZCZBD7lii+GheHb1/8fPvnHAFy4VYIXVm3EbUOFuUtrFmQL1oqKCmRnZ5v8RWxhYQGNRoOsrKxq18nKyqryF3RoaKjYPi8vDzqdzqSNvb09goKCauwTAAwGA/R6vcnUUnl5Abm5wJEjwOTJQGQkcOqUuauihnLp0iVMnToV69atg0qlMnc5ZCZhXTvh1R5Pw0ftjIGeHvgm4mUU/27All/PmLu0ZkG2YL1+/ToqKyvh4uJistzFxQU6na7adXQ6Xa3tH/xbnz4BICEhAfb29uLk7u5e7/E0F9bWgKcn4O8PJCQAvr7A0qXmrooaSnZ2NoqKitCnTx9YWVnBysoK+/btw8cffwwrKytUVlaau0QyAwcbFbq2a4tzN4vNXUqz0CIuA4uNjUVJSYk4Xbp0ydwlNRpGI2AwmLsKaigDBgzAyZMnkZubK04BAQGIiIhAbm4uLC0tzV0imUGpoQL/vVkM1ydam7uUZkG2j9s4OTnB0tIShYWFJssLCwuhVqurXUetVtfa/sG/hYWFcHV1NWnj5+dXYy1KpRJKpfJRhtGsxMYCgwYBHToAt28D69cDmZlAerq5K6OG0qZNG/Ts2dNkWevWrdGuXbsqy6n5mpm+D+FendHB3g4Ft8swP/MQLC0sMKJXN3OX1izIdsRqbW0Nf39/ZGRkiMuMRiMyMjIQXMNlqMHBwSbtAWD37t1i+06dOkGtVpu00ev1OHLkSI190h+KioCxY++fZx0wADh27H6ovviiuSsjooZ0WV+KMVt2oueyFIzevAOONjb4ccIoOLe2NXdpzYKsN4jQarWIjIxEQEAAAgMDkZiYiLKyMkRFRQEAxo4diyeffFK8OnHq1Kno168fPvroI4SHhyM1NRXHjx/H559/DgDiHWLeeecddO3aFZ06dcKcOXPg5uaGYcOGyTmUZmHFCnNXQI1RZmamuUugBrbutXBzl9CsyRqsI0aMwLVr1xAXFwedTgc/Pz+kpaWJFx/l5+fD4k93++jbty/Wr1+P2bNn4z//+Q+6du2K7du3m7xFNWPGDJSVlWHixIkoLi7Gs88+i7S0NF7hSEREjYJCEATB3EU0NL1eD3t7exRcs4baiZ/bamnKK5TwjtsKADg1PxS21ryzZ0tTXnEP3nH3Ly74SZUJW4XRzBVRQysXLNCrJBCXEoejpKQEdnZ2kvXdIq4KJiIiaigMViIiIgkxWImIiCTEYCUiIpIQg5WIiEhCDFYiIiIJMViJiIgkxGAlIiKSEIOViIhIQgxWIiIiCTFYiYiIJMRgJSIikhCDlYiISEIMViIiIgkxWImIiCTEYCUiIpIQg5WIiEhCDFYiIiIJMViJiIgkxGAlIiKSEIOViIhIQrIF682bNxEREQE7Ozs4ODhg/PjxKC0trbX9v/71L3h5ecHGxgYdOnTAm2++iZKSEpN2CoWiypSamirXMIiIiOrFSq6OIyIiUFBQgN27d+Pu3buIiorCxIkTsX79+mrbX716FVevXsWiRYvg7e2NixcvYtKkSbh69Sq2bNli0nbVqlUICwsT5x0cHOQaBhERUb3IEqynT59GWloajh07hoCAAADAJ598gsGDB2PRokVwc3Orsk7Pnj2xdetWcb5Lly5499138frrr+PevXuwsvqjVAcHB6jVajlKJyIieiyyvBWclZUFBwcHMVQBQKPRwMLCAkeOHKlzPyUlJbCzszMJVQCYMmUKnJycEBgYiJUrV0IQhFr7MRgM0Ov1JhMREZEcZDli1el0aN++vekPsrKCo6MjdDpdnfq4fv06FixYgIkTJ5osnz9/Pl544QXY2tpi165d+Oc//4nS0lK8+eabNfaVkJCAefPm1X8gRERE9VSvI9ZZs2ZVe/HQn6fffvvtsYvS6/UIDw+Ht7c35s6da/LYnDlz8Mwzz6B3796YOXMmZsyYgQ8//LDW/mJjY1FSUiJOly5deuwaiYiIqlOvI9a33noL48aNq7VN586doVarUVRUZLL83r17uHnz5kPPjd6+fRthYWFo06YNtm3bhlatWtXaPigoCAsWLIDBYIBSqay2jVKprPExIiIiKdUrWJ2dneHs7PzQdsHBwSguLkZ2djb8/f0BAHv27IHRaERQUFCN6+n1eoSGhkKpVOKbb76BSqV66M/Kzc1F27ZtGZxERNQoyHKOtXv37ggLC0N0dDSSk5Nx9+5dxMTEYOTIkeIVwVeuXMGAAQOwZs0aBAYGQq/XY+DAgSgvL8fatWtNLjJydnaGpaUlvv32WxQWFuLvf/87VCoVdu/ejffeew9vv/22HMMgIiKqN9k+x7pu3TrExMRgwIABsLCwwCuvvIKPP/5YfPzu3bs4c+YMysvLAQA5OTniFcOenp4mfeXl5cHDwwOtWrVCUlIS/v3vf0MQBHh6emLx4sWIjo6WaxhERET1IluwOjo61ngzCADw8PAw+ZhMSEjIQz82ExYWZnJjCCIiosaG9womIiKSEIOViIhIQgxWIiIiCTFYiYiIJMRgJSIikhCDlYiISEIMViIiIgkxWImIiCTEYCUiIpIQg5WIiEhCDFYiIiIJMViJiIgkxGAlIiKSEIOViIhIQgxWIiIiCTFYiYiIJMRgJSIikhCDlYiISEIMViIiIgkxWImIiCTEYCUiIpKQbMF68+ZNREREwM7ODg4ODhg/fjxKS0trXSckJAQKhcJkmjRpkkmb/Px8hIeHw9bWFu3bt8f06dNx7949uYZBRERUL1ZydRwREYGCggLs3r0bd+/eRVRUFCZOnIj169fXul50dDTmz58vztva2or/r6ysRHh4ONRqNQ4dOoSCggKMHTsWrVq1wnvvvSfXUIiIiOpMlmA9ffo00tLScOzYMQQEBAAAPvnkEwwePBiLFi2Cm5tbjeva2tpCrVZX+9iuXbtw6tQp/PDDD3BxcYGfnx8WLFiAmTNnYu7cubC2tq5XnXcqlCivUNRrHWr6yiuUf/o/3+1oif78vJcLPCPWEsn5vMsSrFlZWXBwcBBDFQA0Gg0sLCxw5MgRvPzyyzWuu27dOqxduxZqtRpDhgzBnDlzxKPWrKws9OrVCy4uLmL70NBQTJ48Gb/++it69+5dbZ8GgwEGg0GcLykpAQA8984nsFDaVrsONXflAIA+c741cx1kbkGGgIc3ombJaLi/HxAEQdJ+ZQlWnU6H9u3bm/4gKys4OjpCp9PVuN7o0aPRsWNHuLm54eeff8bMmTNx5swZfPXVV2K/fw5VAOJ8bf0mJCRg3rx5VZZf+XRcXYdERETN1I0bN2Bvby9Zf/UK1lmzZmHhwoW1tjl9+vQjFzNx4kTx/7169YKrqysGDBiA8+fPo0uXLo/cb2xsLLRarThfXFyMjh07Ij8/X9KN2ZTo9Xq4u7vj0qVLsLOzM3c5Da6ljx/gNmjp4we4DUpKStChQwc4OjpK2m+9gvWtt97CuHHjam3TuXNnqNVqFBUVmSy/d+8ebt68WeP50+oEBQUBAM6dO4cuXbpArVbj6NGjJm0KCwsBoNZ+lUollEplleX29vYt8sX0Z3Z2di16G7T08QPcBi19/AC3gYWFtOdb6xWszs7OcHZ2fmi74OBgFBcXIzs7G/7+/gCAPXv2wGg0imFZF7m5uQAAV1dXsd93330XRUVF4lvNu3fvhp2dHby9veszFCIiIlnIcllU9+7dERYWhujoaBw9ehQHDx5ETEwMRo4cKV4RfOXKFXTr1k08Aj1//jwWLFiA7OxsXLhwAd988w3Gjh2L559/Hj4+PgCAgQMHwtvbG2PGjMFPP/2E9PR0zJ49G1OmTKn2iJSIiKihyXa98bp169CtWzcMGDAAgwcPxrPPPovPP/9cfPzu3bs4c+YMysvvX5VlbW2NH374AQMHDkS3bt3w1ltv4ZVXXsG33/5x1aalpSV27NgBS0tLBAcH4/XXX8fYsWNNPvdaF0qlEvHx8S06jFv6Nmjp4we4DVr6+AFuA7nGrxCkvs6YiIioBeMno4mIiCTEYCUiIpIQg5WIiEhCDFYiIiIJtZhgletr7BqrpKQkeHh4QKVSISgoqMqNNf5q8+bN6NatG1QqFXr16oWdO3c2UKXyqc82SElJqfJcq1SqBqxWWvv378eQIUPg5uYGhUKB7du3P3SdzMxM9OnTB0qlEp6enkhJSZG9TjnVdxtkZmZWeQ0oFIpab5famCUkJOBvf/sb2rRpg/bt22PYsGE4c+bMQ9drTvuCR9kGUuwLWkywRkRE4Ndff8Xu3buxY8cO7N+/3+QWijWJjo5GQUGBOH3wwQcNUO3j2bhxI7RaLeLj45GTkwNfX1+EhoZWuRvWA4cOHcKoUaMwfvx4nDhxAsOGDcOwYcPwyy+/NHDl0qnvNgDu333mz8/1xYsXG7BiaZWVlcHX1xdJSUl1ap+Xl4fw8HD0798fubm5mDZtGiZMmID09HSZK5VPfbfBA2fOnDF5Hfz1vudNxb59+zBlyhQcPnxY/PrOgQMHoqysrMZ1mtu+4FG2ASDBvkBoAU6dOiUAEI4dOyYu+/777wWFQiFcuXKlxvX69esnTJ06tQEqlFZgYKAwZcoUcb6yslJwc3MTEhISqm0/fPhwITw83GRZUFCQ8MYbb8hap5zquw1WrVol2NvbN1B1DQuAsG3btlrbzJgxQ+jRo4fJshEjRgihoaEyVtZw6rIN9u7dKwAQbt261SA1NbSioiIBgLBv374a2zTHfcGf1WUbSLEvaBFHrA/7GrvarFu3Dk5OTujZsydiY2PFG1o0VhUVFcjOzoZGoxGXWVhYQKPRICsrq9p1srKyTNoD97+Or6b2jd2jbAMAKC0tRceOHeHu7o6hQ4fi119/bYhyG4Xm9hp4HH5+fnB1dcWLL76IgwcPmrscyTz4uszabjjf3F8HddkGwOPvC1pEsD7O19itXbsWe/fuRWxsLL788ku8/vrrcpf7WK5fv47Kyspqv16vprHW9HV8TfXc0qNsAy8vL6xcuRJff/011q5dC6PRiL59++Ly5csNUbLZ1fQa0Ov1uHPnjpmqaliurq5ITk7G1q1bsXXrVri7uyMkJAQ5OTnmLu2xGY1GTJs2Dc888wx69uxZY7vmti/4s7puAyn2BbJ8H2tDaapfY0eNT3BwMIKDg8X5vn37onv37vjss8+wYMECM1ZGDcXLywteXl7ifN++fXH+/HksWbIEX375pRkre3xTpkzBL7/8ggMHDpi7FLOp6zaQYl/QpIPV3F9j1xg5OTnB0tJS/Dq9BwoLC2scq1qtrlf7xu5RtsFftWrVCr1798a5c+fkKLHRqek1YGdnBxsbGzNVZX6BgYFNPoxiYmLECzafeuqpWts2t33BA/XZBn/1KPuCJv1WsLOzM7p161brZG1tbfI1dg9I8TV2jZG1tTX8/f2RkZEhLjMajcjIyDD5K+zPgoODTdoD97+Or6b2jd2jbIO/qqysxMmTJxv1cy2l5vYakEpubm6TfQ0IgoCYmBhs27YNe/bsQadOnR66TnN7HTzKNvirR9oXPNalT01IWFiY0Lt3b+HIkSPCgQMHhK5duwqjRo0SH798+bLg5eUlHDlyRBAEQTh37pwwf/584fjx40JeXp7w9ddfC507dxaef/55cw2hzlJTUwWlUimkpKQIp06dEiZOnCg4ODgIOp1OEARBGDNmjDBr1iyx/cGDBwUrKyth0aJFwunTp4X4+HihVatWwsmTJ801hMdW320wb948IT09XTh//ryQnZ0tjBw5UlCpVMKvv/5qriE8ltu3bwsnTpwQTpw4IQAQFi9eLJw4cUK4ePGiIAiCMGvWLGHMmDFi+//+97+Cra2tMH36dOH06dNCUlKSYGlpKaSlpZlrCI+tvttgyZIlwvbt24WzZ88KJ0+eFKZOnSpYWFgIP/zwg7mG8FgmT54s2NvbC5mZmUJBQYE4lZeXi22a+77gUbaBFPuCFhOsN27cEEaNGiU88cQTgp2dnRAVFSXcvn1bfDwvL08AIOzdu1cQBEHIz88Xnn/+ecHR0VFQKpWCp6enMH36dKGkpMRMI6ifTz75ROjQoYNgbW0tBAYGCocPHxYf69evnxAZGWnSftOmTcLTTz8tWFtbCz169BC+++67Bq5YevXZBtOmTRPburi4CIMHDxZycnLMULU0Hnx05K/TgzFHRkYK/fr1q7KOn5+fYG1tLXTu3FlYtWpVg9ctpfpug4ULFwpdunQRVCqV4OjoKISEhAh79uwxT/ESqG7sAEye1+a+L3iUbSDFvoBfG0dERCShJn2OlYiIqLFhsBIREUmIwUpERCQhBisREZGEGKxEREQSYrASERFJiMFKREQkIQYrERGRhBisREREEmKwEhERSYjBSkREJCEGKxERkYT+PwjoRED23gYhAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "agent = Agent(\n",
        "    nrow_maze=2,\n",
        "    ncol_maze=3,\n",
        "    seed=0,\n",
        "    rewards={'step': 0, 'goal': 10}\n",
        ")\n",
        "\n",
        "# Initiating the maze\n",
        "agent.init_maze(maze_density=1)\n",
        "\n",
        "# Ploting the maze\n",
        "plot_matrix(agent.S, goal_coords=agent.goal_coords, hole_coords=agent.wall_coords, start_coords=agent.start_coords, title=\"Maze\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the initial Q table"
      ],
      "metadata": {
        "id": "THK6SvZrNQQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_Q_Table(\n",
        "    S=agent.S,\n",
        "    Q=agent.Q,\n",
        "    goal_coords=agent.goal_coords,\n",
        "    wall_coords=agent.wall_coords,\n",
        "    start_coords=agent.start_coords,\n",
        "    title=\"Init Q Table\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "g4Q4G0nQCPUN",
        "outputId": "42cb7d43-c830-4ad1-c39a-eab7a1fb6ba4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1.   https://github.com/Eligijus112/rl-snake-game\n",
        "2.   Sutton, Richard S., and Andrew G. Barto. Reinforcement learning: An introduction. MIT press, 2018.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hwXoVxHBp8MT"
      }
    }
  ]
}